% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ERAAnalyze.R
\name{ERAAnalyze}
\alias{ERAAnalyze}
\title{Analyze Outcome Ratios}
\usage{
ERAAnalyze(Data, rmOut = T, Aggregate.By, ROUND = 5, Fast = F)
}
\arguments{
\item{Data}{A preapred ERA dataset (see PrepareERA function)}

\item{rmOut}{Logical T/F. If TRUE extreme outliers are dectected and removed for each combination of grouping variables.}

\item{Aggregate.By}{Column names for grouping variables. Statistics will be compiled for each combination of these variables.}

\item{ROUND}{Integer value for the number of decimal places numeric columns in the output dataset should be rounded to.}

\item{Fast}{Logical T/F. If \code{FALSE} then lmer and lm models are used to estimate means, errors and significance if sufficient data exist.}
}
\value{
A data.table of response ratios and percentage change values, each row representing a combination of the grouping variables specified in the Aggregrate.By parameter. \code{RR} = outcome response ratio $log(MeanT/MeanC)$, \code{PC} = outcome proportional change $MeanT/MeanC$.

Output columns when \code{Fast} is \code{TRUE}:
\itemize{
\item \code{Observations} = no. rows of data
\item \code{Studies} = no. studies (publications)
\item \code{Sites} = no. of geographic locations
\item \code{RR.Shapiro.Sig} = P-value from a Shapiro-Wilk test of RR
\item \code{RR} = weighted mean of RR
\item \code{RR} = weighted median of RR
\item \code{RR.se} = weighted standard error of RR
\item \code{RR.var} = weighted variance of RR
\item \code{RR.Quantiles05} = weighted quantiles of the RR
\item \code{PC.Shapiro.Sig} = P-value from a Shapiro-Wilk test of PC
\item \code{PC} = weighted mean of PC
\item \code{PC} = weighted median of PC
\item \code{PC.se} = weighted standard error of PC
\item \code{PC.var} = weighted variance of PC
\item \code{PC.Quantiles05} = weighted quantiles of the PC
\item \code{PC.pc} = percent change based on PC (\verb{100 x PC - 100})
\item \code{PC.pc.se.low} = lower standard error confidence interval of \% change based on PC
\item \code{PC.pc.se.high} = upper standard error confidence interval of \% change based on PC
\item \code{RR.pc} = \% change based on RR (\verb{100 x exp(RR) - 100})
\item \code{RR.pc.se.low} = lower standard error confidence interval of \% change based on RR
\item \code{RR.pc.se.high} = upper standard error confidence interval of \% change based on RR
\item \code{RR.pc.jen} = \% change based on RR with correction for Jensen inequality (\verb{100 x exp(RR+RR.var/2) - 100})
\item \code{RR.pc.jen.low} = lower standard error confidence interval of \% change based on RR with correction for Jensen inequality
\item \code{RR.pc.jen.high} = upper standard error confidence interval of \% change based on RR with correction for Jensen inequality
}

Where all units are indentical for the grouping variables (row) then the following columns will have values (else they are NA):
\itemize{
\item \code{Units} = the unit of recording for an outcome (e.g. kg/ha)
\item \code{MeanT.Obs} = number of experimental treatment observations
\item \code{MeanT} = weighted mean of experimental treatment outcome values
\item \code{MeanT.se} = weighted standard error of experimental treatment outcome values
\item \code{MeanC.Obs} = number of control treatment observations
\item \code{MeanC} = weighted mean of control treatment outcome values
\item \code{MeanC.se} = weighted standard error of contol treatment outcome values
}

When \code{Fast = TRUE} means, standard errors and confidence intervals are replaced by estimates from, in order of preference, lmer then lm models, if the model minimum data
requirements are met. Percentage change data is then calculated from the updated estimates.

Additional columns when \code{Fast = FALSE}:
\itemize{
\item \code{Model} = type of model that was applied to data, \code{NA} = no model was applied.
\item \code{RR.t.value} = t statistic from RR model
\item \verb{RR.Pr(>|t|)} = probability that the outcome is not equal to zero from RR model
\item \code{RR.Sigma2} = RR model sigma2
\item \code{PC.t.value} = t statistic from PC model
\item \verb{PC.Pr(>|t|)} = probability that the outcome is not equal to zero from PC model
\item \code{PC.Sigma2} = PC model sigma2
}
}
\description{
This function analyzes outcome ratios in the ERA dataset for each combination of grouping variables as specified by column names in the \code{Aggregate.By} parameter. We suggest
applying the \code{ERA.Prepare} function to data before using with this function.
}
\details{
Several actions are or can be applied by this function:
\enumerate{
\item Outlier Removal: Outliers are defined using an extreme outliers method where values above or below $3*IQR$ (interquartile range) are removed. The ERA outcome variables
analyzed by this function are ratios between am experimental treatment and control outcome and should be approximately normally distributed. When the control approaches
zero (e.g. yield collapse) this skews the distribution of the outcome ratio producing extremely high values tending to infinity and requiring outlier removal.
The use of outcome ratios, whilst necessary to standardize outcomes between studies, means this approach is inappropriate to study nil outcomes (e.g. total crop yield failure),
a binomial approach would be better for such instances. Outlier removal is optional and enabled if the rmOut parameter is set to TRUE (default).
\item Weighting: Within-study variance measures for mean outcomes are infrequently reported in agricultural literature, so traditional meta-analytic approaches cannot be applied
to most ERA outcomes. Therefore individual observations are up-weighted by replication and down-weighted by the number of observations submitted from the same study (colname =
Code) for each combination of grouping variables. Studies with more replications are likely to produce less variable information than studies with fewer. Controlling for
the number of #' observations contributed by a study to the dataset weights each study equally.   As such, outcome ratios are weighted according to:
\code{Weighting = ((RepsE * RepsC)/(RepsE)+(RepsC))/(Ns)}  where \code{Rep} is the number of replications for \code{RepC} the control and \code{RepE} the experimental
treatment, and \code{Ns} is the total number of observations contributed to the overall dataset by the study to which the observation belongs.
\item Test of Normality: A Shapiro-Wilk test ( \link[stats]{shapiro.test}) is applied to raw and log-transformed outcome ratios for each combination of grouping variables. This can be used
to judge whether values based on mean proportional change, mean response ratio or median proportional change should be used to evaluate practice performance.
\item Statistics calculated (in all cases na.rm=T):
\itemize{
\item \emph{weighted means} use the \link[stats]{weighted.mean} function
\item \emph{weighted medians} use the \link[spatstat.geom]{weighted.median} function
\item \emph{weighted standard errors} use the \link[diagis]{weighted_se} function
\item \emph{weighted variance} uses the \link[Hmisc]{wtd.var} function
\item \emph{weighted quantiles} use the \link[spatstat.geom]{weighted.median} (\code{weighted.quantile}) function with \code{probs=seq(0,1,0.25)}
}
\item Response ratios are back-transformed and converted to \% change with and without a correction for the Jensen inequality.
The correction applied is as per \href{https://www.biorxiv.org/content/10.1101/179358v1}{Tandini & Mehrabi 2017}.
\item When \code{Fast = FALSE} where minimum data requirements are met linear-mixed effects or linear model is applied to the data to generate means, standard errors and variance.
\itemize{
\item Linear mixed effects models use \link[lmer]{lme4} where outcomes from a grouping variable combination are from at least three sites of which two must have at
least three observations. The model is weighted and includes a random intercept for site (\code{lmer(Value~1 + (1|Site),weights=Weights)}).
\item If the minimum data requirements for the lmer are not met then a linear model with weights is applied (\code{lm(Value~1,weights=Weights)}) if there are at least 5 outcome observations for the grouping variable combination.
\item If the minimum data requirements for the lm are not met no test is applied to the outcome values.
}
}
}
